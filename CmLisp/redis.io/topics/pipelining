<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <title>Using pipelining to speedup Redis queries â€“ Redis</title>
    <link href='/styles.css' rel='stylesheet'>
    <link href='/images/favicon.png' rel='shortcut icon'>
    <link href='/opensearch.xml' rel='search' title='Look up a Redis command' type='application/opensearchdescription+xml'>
    <meta content='width=device-width, minimum-scale=1.0, maximum-scale=1.0' name='viewport'>
    <script>
       var _gaq = _gaq || [];
       _gaq.push(['_setAccount', 'UA-20243082-1']);
       _gaq.push(['_trackPageview']);
      
       (function() {
         var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
         ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
         var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
       })();
    </script>
  </head>
  <body class='topics pipelining'>
    <div class='mobile-menu slideout-menu'>
      <header class='menu-header'></header>
      <section class='menu-section'>
        <ul class='menu-section-list'>
          <li>
            <a class='home' href='/'>Home</a>
          </li>
          <li>
            <a href='/commands'>Commands</a>
          </li>
          <li>
            <a href='/clients'>Clients</a>
          </li>
          <li>
            <a href='/documentation'>Documentation</a>
          </li>
          <li>
            <a href='/community'>Community</a>
          </li>
          <li>
            <a href='/download'>Download</a>
          </li>
          <li>
            <a href='/modules'>Modules</a>
          </li>
          <li>
            <a href='/support'>Support</a>
          </li>
        </ul>
      </section>
    </div>
    <div class='site-wrapper'>
      <header class='site-header'>
        <nav class='container'>
          <div class='mobile-header'>
            <button class='btn-hamburger js-slideout-toggle'>
              <span class='fa fa-bars'></span>
            </button>
            <a class='home' href='/'>
              <img alt='Redis' src='/images/redis-white.png'>
            </a>
          </div>
          <div class='desktop-header'>
            <a class='home' href='/'>
              <img alt='Redis' src='/images/redis-white.png'>
            </a>
            <a href='/commands'>Commands</a>
            <a href='/clients'>Clients</a>
            <a href='/documentation'>Documentation</a>
            <a href='/community'>Community</a>
            <a href='/download'>Download</a>
            <a href='/modules'>Modules</a>
            <a href='/support'>Support</a>
          </div>
        </nav>
      </header>
      <div class='site-content'>
        <div class='text'>
          <article id='topic'>
            <span id="using-pipelining-to-speedup-redis-queries" class=anchor></span><h1 ><a href="#using-pipelining-to-speedup-redis-queries" class=anchor-link>*</a>Using pipelining to speedup Redis queries</h1>
            
            <span id="requestresponse-protocols-and-rtt" class=anchor></span><h2 ><a href="#requestresponse-protocols-and-rtt" class=anchor-link>*</a>Request/Response protocols and RTT</h2>
            
            <p>Redis is a TCP server using the client-server model and what is called a <em>Request/Response</em> protocol.</p>
            
            <p>This means that usually a request is accomplished with the following steps:</p>
            
            <ul>
            <li>The client sends a query to the server, and reads from the socket, usually in a blocking way, for the server response.</li>
            <li>The server processes the command and sends the response back to the client.</li>
            </ul>
            
            <p>So for instance a four commands sequence is something like this:</p>
            
            <ul>
            <li><em>Client:</em> INCR X</li>
            <li><em>Server:</em> 1</li>
            <li><em>Client:</em> INCR X</li>
            <li><em>Server:</em> 2</li>
            <li><em>Client:</em> INCR X</li>
            <li><em>Server:</em> 3</li>
            <li><em>Client:</em> INCR X</li>
            <li><em>Server:</em> 4</li>
            </ul>
            
            <p>Clients and Servers are connected via a networking link. Such a link can be very fast (a loopback interface) or very slow (a connection established over the Internet with many hops between the two hosts). Whatever the network latency is, there is a time for the packets to travel from the client to the server, and back from the server to the client to carry the reply.</p>
            
            <p>This time is called RTT (Round Trip Time). It is very easy to see how this can affect the performances when a client needs to perform many requests in a row (for instance adding many elements to the same list, or populating a database with many keys). For instance if the RTT time is 250 milliseconds (in the case of a very slow link over the Internet), even if the server is able to process 100k requests per second, we&#39;ll be able to process at max four requests per second.</p>
            
            <p>If the interface used is a loopback interface, the RTT is much shorter (for instance my host reports 0,044 milliseconds pinging 127.0.0.1), but it is still a lot if you need to perform many writes in a row.</p>
            
            <p>Fortunately there is a way to improve this use case.</p>
            
            <span id="redis-pipelining" class=anchor></span><h2 ><a href="#redis-pipelining" class=anchor-link>*</a>Redis Pipelining</h2>
            
            <p>A Request/Response server can be implemented so that it is able to process new requests even if the client didn&#39;t already read the old responses. This way it is possible to send <em>multiple commands</em> to the server without waiting for the replies at all, and finally read the replies in a single step.</p>
            
            <p>This is called pipelining, and is a technique widely in use since many decades. For instance many POP3 protocol implementations already supported this feature, dramatically speeding up the process of downloading new emails from the server.</p>
            
            <p>Redis supports pipelining since the very early days, so whatever version you are running, you can use pipelining with Redis. This is an example using the raw netcat utility:</p>
            
            <pre><code>$ (printf &quot;PING\r\nPING\r\nPING\r\n&quot;; sleep 1) | nc localhost 6379&#x000A;+PONG&#x000A;+PONG&#x000A;+PONG&#x000A;</code></pre>
            
            <p>This time we are not paying the cost of RTT for every call, but just one time for the three commands.</p>
            
            <p>To be very explicit, with pipelining the order of operations of our very first example will be the following:</p>
            
            <ul>
            <li><em>Client:</em> INCR X</li>
            <li><em>Client:</em> INCR X</li>
            <li><em>Client:</em> INCR X</li>
            <li><em>Client:</em> INCR X</li>
            <li><em>Server:</em> 1</li>
            <li><em>Server:</em> 2</li>
            <li><em>Server:</em> 3</li>
            <li><em>Server:</em> 4</li>
            </ul>
            
            <p><strong>IMPORTANT NOTE</strong>: While the client sends commands using pipelining, the server will be forced to queue the replies, using memory. So if you need to send a lot of commands with pipelining, it is better to send them as batches having a reasonable number, for instance 10k commands, read the replies, and then send another 10k commands again, and so forth. The speed will be nearly the same, but the additional memory used will be at max the amount needed to queue the replies for this 10k commands.</p>
            
            <span id="it39s-not-just-a-matter-of-rtt" class=anchor></span><h2 ><a href="#it39s-not-just-a-matter-of-rtt" class=anchor-link>*</a>It&#39;s not just a matter of RTT</h2>
            
            <p>Pipelining is not just a way in order to reduce the latency cost due to the
            round trip time, it actually improves by a huge amount the total operations
            you can perform per second in a given Redis server. This is the result of the
            fact that, without using pipelining, serving each command is very cheap from
            the point of view of accessing the data structures and producing the reply,
            but it is very costly from the point of view of doing the socket I/O. This
            involves calling the <code>read()</code> and <code>write()</code> syscall, that means going from user
            land to kernel land. The context switch is a huge speed penalty.</p>
            
            <p>When pipelining is used, many commands are usually read with a single <code>read()</code>
            system call, and multiple replies are delivered with a single <code>write()</code> system
            call. Because of this, the number of total queries performed per second
            initially increases almost linearly with longer pipelines, and eventually
            reaches 10 times the baseline obtained not using pipelining, as you can
            see from the following graph:</p>
            
            <p><img src="http://redis.io/images/redisdoc/pipeline_iops.png" alt="Pipeline size and IOPs"></p>
            
            <span id="some-real-world-code-example" class=anchor></span><h2 ><a href="#some-real-world-code-example" class=anchor-link>*</a>Some real world code example</h2>
            
            <p>In the following benchmark we&#39;ll use the Redis Ruby client, supporting pipelining, to test the speed improvement due to pipelining:</p>
            
            <pre><code>require &#39;rubygems&#39;&#x000A;require &#39;redis&#39;&#x000A;&#x000A;def bench(descr)&#x000A;    start = Time.now&#x000A;    yield&#x000A;    puts &quot;#{descr} #{Time.now-start} seconds&quot;&#x000A;end&#x000A;&#x000A;def without_pipelining&#x000A;    r = Redis.new&#x000A;    10000.times {&#x000A;        r.ping&#x000A;    }&#x000A;end&#x000A;&#x000A;def with_pipelining&#x000A;    r = Redis.new&#x000A;    r.pipelined {&#x000A;        10000.times {&#x000A;            r.ping&#x000A;        }&#x000A;    }&#x000A;end&#x000A;&#x000A;bench(&quot;without pipelining&quot;) {&#x000A;    without_pipelining&#x000A;}&#x000A;bench(&quot;with pipelining&quot;) {&#x000A;    with_pipelining&#x000A;}&#x000A;</code></pre>
            
            <p>Running the above simple script will provide the following figures in my Mac OS X system, running over the loopback interface, where pipelining will provide the smallest improvement as the RTT is already pretty low:</p>
            
            <pre><code>without pipelining 1.185238 seconds&#x000A;with pipelining 0.250783 seconds&#x000A;</code></pre>
            
            <p>As you can see, using pipelining, we improved the transfer by a factor of five.</p>
            
            <span id="pipelining-vs-scripting" class=anchor></span><h2 ><a href="#pipelining-vs-scripting" class=anchor-link>*</a>Pipelining VS Scripting</h2>
            
            <p>Using <a href="/commands/eval">Redis scripting</a> (available in Redis version 2.6 or greater) a number of use cases for pipelining can be addressed more efficiently using scripts that perform a lot of the work needed at the server side. A big advantage of scripting is that it is able to both read and write data with minimal latency, making operations like <em>read, compute, write</em> very fast (pipelining can&#39;t help in this scenario since the client needs the reply of the read command before it can call the write command).</p>
            
            <p>Sometimes the application may also want to send <a href="/commands/eval">EVAL</a> or <a href="/commands/evalsha">EVALSHA</a> commands in a pipeline. This is entirely possible and Redis explicitly supports it with the <a href="http://redis.io/commands/script-load">SCRIPT LOAD</a> command (it guarantees that <a href="/commands/evalsha">EVALSHA</a> can be called without the risk of failing).</p>
            
            <span id="appendix-why-a-busy-loops-are-slow-even-on-the-loopback-interface" class=anchor></span><h2 ><a href="#appendix-why-a-busy-loops-are-slow-even-on-the-loopback-interface" class=anchor-link>*</a>Appendix: why a busy loops are slow even on the loopback interface?</h2>
            
            <p>Even with all the background covered in this page, you may still wonder why
            a Redis benchmark like the following (in pseudo code), is slow even when
            executed in the loopback interface, when the server and the client are running
            in the same physical machine:</p>
            
            <pre><code>FOR-ONE-SECOND:&#x000A;    Redis.SET(&quot;foo&quot;,&quot;bar&quot;)&#x000A;END&#x000A;</code></pre>
            
            <p>After all if both the Redis process and the benchmark are running in the same
            box, isn&#39;t this just messages copied via memory from one place to another without
            any actual latency and actual networking involved?</p>
            
            <p>The reason is that processes in a system are not always running, actually it is
            the kernel scheduler that let the process run, so what happens is that, for
            instance, the benchmark is allowed to run, reads the reply from the Redis server
            (related to the last command executed), and writes a new command. The command is
            now in the loopback interface buffer, but in order to be read by the server, the
            kernel should schedule the server process (currently blocked in a system call)
            to run, and so forth. So in practical terms the loopback interface still involves
            network-alike latency, because of how the kernel scheduler works.</p>
            
            <p>Basically a busy loop benchmark is the silliest thing that can be done when
            metering performances in a networked server. The wise thing is just avoiding
            benchmarking in this way.</p>
          </article>
        </div>
      </div>
      <footer class='site-footer'>
        <div class='container'>
          <p>
            This website is
            <a href="https://github.com/antirez/redis-io">open source software</a>.
            See all <a href="/topics/sponsors">credits</a>.
          </p>
          <div class='sponsor'>
            Sponsored by
            <a href='https://redislabs.com/'>
              <img alt='Redis Labs' height='25' src='/images/redislabs.png' title='Get a Managed Redis' width='128'>
            </a>
          </div>
        </div>
      </footer>
    </div>
    <script src='https://ajax.googleapis.com/ajax/libs/jquery/1.4/jquery.min.js'></script>
    <script src='/app.js?1480208557'></script>
  </body>
</html>
